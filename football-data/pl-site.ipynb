{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Premier League Football Data with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scrape the clubs page and make a list of each team page\n",
    "- Scrape each team’s page for players and make a list of each player\n",
    "- Scrape each player page and take their height, weight and apps number\n",
    "- Save this into a table for later analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Read the Clubs page and list each team_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download the html of the page and identify the links pointing towards the teams. We then save this into a list that we can use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take site and structure html\n",
    "page = requests.get('https://www.premierleague.com/clubs')\n",
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the page's CSS classes, extract all links pointing to a team\n",
    "linkLocation = tree.cssselect('.indexItem')\n",
    "\n",
    "#Create an empty list for us to send each team's link to\n",
    "teamLinks = []\n",
    "\n",
    "#For each link...\n",
    "for i in range(0,20):\n",
    "    \n",
    "    #...Find the page the link is going to...\n",
    "    temp = linkLocation[i].attrib['href']\n",
    "    \n",
    "    #...Add the link to the website domain...\n",
    "    temp = \"http://www.premierleague.com/\" + temp\n",
    "    \n",
    "    #...Change the link text so that it points to the squad list, not the page overview...\n",
    "    temp = temp.replace(\"overview\", \"squad\")\n",
    "    \n",
    "    #...Add the finished link to our teamLinks list...\n",
    "    teamLinks.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Read through each team’s list of players and create a link for each one_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our process here is very similar to the first step, now we are just looking to create a longer list of each player, not each team.\n",
    "\n",
    "The main difference is that we will create two links, as the data that we need is across both the player overview page, and the player stats page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty lists for player links\n",
    "playerLink1 = []\n",
    "playerLink2 = []\n",
    "\n",
    "#For each team link page...\n",
    "for i in range(len(teamLinks)):\n",
    "    \n",
    "    #...Download the team page and process the html code...\n",
    "    squadPage = requests.get(teamLinks[i])\n",
    "    squadTree = html.fromstring(squadPage.content)\n",
    "    \n",
    "    #...Extract the player links...\n",
    "    playerLocation = squadTree.cssselect('.playerOverviewCard')\n",
    "\n",
    "    #...For each player link within the team page...\n",
    "    for i in range(len(playerLocation)):\n",
    "        \n",
    "        #...Save the link, complete with domain...\n",
    "        playerLink1.append(\"http://www.premierleague.com/\" + playerLocation[i].attrib['href'])\n",
    "        \n",
    "        #...For the second link, change the page from player overview to stats\n",
    "        playerLink2.append(playerLink1[i].replace(\"overview\", \"stats\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Scrape each player’s page for their age, apps, height and weight data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start this step by defining empty lists for the datapoints we intend to capture. Afterwards, we’ll work through each player link to save the player’s details. We will also add a little line of code to add in some blank data if the site is missing any details – this should allow us to run without any errors. After collecting each player’s data, we will simply add it to the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists for each variable\n",
    "Name = []\n",
    "Team = []\n",
    "Age = []\n",
    "Apps = []\n",
    "HeightCM = []\n",
    "WeightKG = []\n",
    "\n",
    "\n",
    "#Populate lists with each player\n",
    "\n",
    "#For each player...\n",
    "for i in range(len(playerLink1)):\n",
    "\n",
    "    #...download and process the two pages collected earlier...\n",
    "    playerPage1 = requests.get(playerLink1[i])\n",
    "    playerTree1 = html.fromstring(playerPage1.content)\n",
    "    playerPage2 = requests.get(playerLink2[i])\n",
    "    playerTree2 = html.fromstring(playerPage2.content)\n",
    "\n",
    "    #...find the relevant datapoint for each player, starting with name...\n",
    "    tempName = str(playerTree1.cssselect('div.name')[0].text_content())\n",
    "    \n",
    "    #...and team, but if there isn't a team, return \"BLANK\"...\n",
    "    try:\n",
    "        tempTeam = str(playerTree1.cssselect('.table:nth-child(1) .long')[0].text_content())\n",
    "    except IndexError:\n",
    "        tempTeam = str(\"BLANK\")\n",
    "    \n",
    "    #...and age, but if this isn't there, leave a blank 'no number' number...\n",
    "    try:  \n",
    "        tempAge = int(playerTree1.cssselect('.pdcol2 li:nth-child(1) .info')[0].text_content())\n",
    "    except IndexError:\n",
    "        tempAge = float('NaN')\n",
    "\n",
    "    #...and appearances. This is a bit of a mess on the page, so tidy it first...\n",
    "    try:\n",
    "        tempApps = playerTree2.cssselect('.statappearances')[0].text_content()\n",
    "        tempApps = int(re.search(r'\\d+', tempApps).group())\n",
    "    except IndexError:\n",
    "        tempApps = float('NaN')\n",
    "\n",
    "    #...and height. Needs tidying again...\n",
    "    try:\n",
    "        tempHeight = playerTree1.cssselect('.pdcol3 li:nth-child(1) .info')[0].text_content()\n",
    "        tempHeight = int(re.search(r'\\d+', tempHeight).group())\n",
    "    except IndexError:\n",
    "        tempHeight = float('NaN')\n",
    "\n",
    "    #...and weight. Same with tidying and returning blanks if it isn't there\n",
    "    try:\n",
    "        tempWeight = playerTree1.cssselect('.pdcol3 li+ li .info')[0].text_content()\n",
    "        tempWeight = int(re.search(r'\\d+', tempWeight).group())\n",
    "    except IndexError:\n",
    "        tempWeight = float('NaN')\n",
    "\n",
    "\n",
    "    #Now that we have a player's full details - add them all to the lists\n",
    "    Name.append(tempName)\n",
    "    Team.append(tempTeam)\n",
    "    Age.append(tempAge)\n",
    "    Apps.append(tempApps)\n",
    "    HeightCM.append(tempHeight)\n",
    "    WeightKG.append(tempWeight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Saving our lists to a dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame from lists\n",
    "df = pd.DataFrame(\n",
    "    {'Name':Name,\n",
    "     'Team':Team,\n",
    "     'Age':Age,\n",
    "     'Apps':Apps,\n",
    "     'HeightCM':HeightCM,\n",
    "     'WeightKG':WeightKG})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"EPLData.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7894a52d68d58fbd92560d3706c1758f91e373e9093849d544b4761ad70d7c45"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('webScraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
